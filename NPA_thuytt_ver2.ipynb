{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "registered-bones",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "combined-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "heard-image",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sapo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1002681074</td>\n",
       "      <td>4243622</td>\n",
       "      <td>Galaxy S21 Ultra được trang bị pin 5.000 mAh n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002681074</td>\n",
       "      <td>4243459</td>\n",
       "      <td>Thấy nòng súng súng thò ra khỏi cửa, nữ cảnh s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002681074</td>\n",
       "      <td>4238172</td>\n",
       "      <td>Sau khi có chức vô địch Australia Mở rộng, Nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1002681074</td>\n",
       "      <td>4237883</td>\n",
       "      <td>Novak Djokovic đạt tỷ lệ thắng 81% trước các đ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1002681074</td>\n",
       "      <td>4231206</td>\n",
       "      <td>Một người không thể đi hơn một xe máy ra đường...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>1003347668</td>\n",
       "      <td>4154347</td>\n",
       "      <td>Trên chương trình El Larguero của đài Cadena S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>1003347668</td>\n",
       "      <td>4154384</td>\n",
       "      <td>Tiền đạo Robert Lewandowski nói anh xứng đáng ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>1003347668</td>\n",
       "      <td>4155165</td>\n",
       "      <td>Hầu hết những chỉ số tấn công của Lionel Messi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>1003347668</td>\n",
       "      <td>4155219</td>\n",
       "      <td>Indonesia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2730</th>\n",
       "      <td>1003347668</td>\n",
       "      <td>4155786</td>\n",
       "      <td>Nếu Lionel Messi gia nhập Man City, những ngườ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2617 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             uid  articleID                                               sapo\n",
       "0     1002681074    4243622  Galaxy S21 Ultra được trang bị pin 5.000 mAh n...\n",
       "1     1002681074    4243459  Thấy nòng súng súng thò ra khỏi cửa, nữ cảnh s...\n",
       "2     1002681074    4238172  Sau khi có chức vô địch Australia Mở rộng, Nov...\n",
       "3     1002681074    4237883  Novak Djokovic đạt tỷ lệ thắng 81% trước các đ...\n",
       "4     1002681074    4231206  Một người không thể đi hơn một xe máy ra đường...\n",
       "...          ...        ...                                                ...\n",
       "2726  1003347668    4154347  Trên chương trình El Larguero của đài Cadena S...\n",
       "2727  1003347668    4154384  Tiền đạo Robert Lewandowski nói anh xứng đáng ...\n",
       "2728  1003347668    4155165  Hầu hết những chỉ số tấn công của Lionel Messi...\n",
       "2729  1003347668    4155219                                          Indonesia\n",
       "2730  1003347668    4155786  Nếu Lionel Messi gia nhập Man City, những ngườ...\n",
       "\n",
       "[2617 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/traindata_demo.csv')\n",
    "df.dropna(subset=['sapo'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acute-blogger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.uid.unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "careful-median",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df.groupby('uid')\n",
    "len_group = []\n",
    "for name, group in tmp:\n",
    "    len_group.append(group['articleID'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "uniform-table",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "leng    2289\n",
       "dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets = pd.DataFrame()\n",
    "baskets['leng'] = len_group\n",
    "baskets[baskets.leng <10].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-amplifier",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "disciplinary-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lấy user mà clicked articleID => article khác của user khác\n",
    "def get_negative_sample(articleID, df, npratio=4):\n",
    "    uid = df[df.articleID==articleID].uid.values[0]\n",
    "    tmp_df = df[df.uid != uid].sample(4)\n",
    "    return [articleID] + list(tmp_df.articleID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "mobile-medicare",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_clicked(df, npratio=4):\n",
    "    uids = df.uid.unique()\n",
    "    user_count = len(uids)\n",
    "    userid_dict = {}\n",
    "    for uid in uids:\n",
    "        if uid not in userid_dict:\n",
    "            userid_dict[uid] = len(userid_dict) # map uid_raw -> 0 1 2\n",
    "\n",
    "    all_train_id = []\n",
    "    all_train_pn = []\n",
    "    all_label = []\n",
    "    \n",
    "    all_test_id = []\n",
    "    all_test_pn = []\n",
    "    all_test_label = []\n",
    "    all_test_index = []\n",
    "    \n",
    "    all_user_pos = []\n",
    "    all_test_user_pos = []\n",
    "\n",
    "    for uid in uids:\n",
    "        tmp_df = df[df.uid==uid] # df of uid\n",
    "        clicked_news = tmp_df.articleID.values\n",
    "        clicked_news = set(clicked_news)  # get all unique article which user clicked\n",
    "        \n",
    "        for idx in range(len(tmp_df)-1):\n",
    "            line = tmp_df.iloc[idx]\n",
    "            all_train_pn.append(get_negative_sample(line.articleID, df))\n",
    "            all_label.append([1,0,0,0,0])\n",
    "            all_train_id.append(userid_dict[uid])\n",
    "\n",
    "            remain_clicked = list(clicked_news - set([line.articleID]))\n",
    "            remain_clicked = random.sample(remain_clicked, min(50, len(remain_clicked)))\n",
    "            remain_clicked += [0] * (50-len(remain_clicked)) # <50 cho = 0\n",
    "            all_user_pos.append(remain_clicked)\n",
    "        \n",
    "        # get the last line for testing\n",
    "        sess_index = []\n",
    "        sess_index.append(len(all_test_pn))\n",
    "\n",
    "        line = tmp_df.iloc[-1]\n",
    "        all_test_pn += get_negative_sample(line.articleID, df)\n",
    "        sess_index.append(len(all_test_pn))\n",
    "        all_test_index.append(sess_index)\n",
    "        all_test_label += [1,0,0,0,0]\n",
    "        all_test_id += [userid_dict[uid]] * (npratio+1)\n",
    "        allpos = random.sample(clicked_news, min(50, len(clicked_news)))\n",
    "        allpos += [0] * (50-len(allpos))\n",
    "        for i in range(5):\n",
    "            all_test_user_pos.append(allpos)\n",
    "    \n",
    "    all_train_pn = np.array(all_train_pn,dtype='int32')\n",
    "    all_label = np.array(all_label,dtype='int32')\n",
    "    all_train_id = np.array(all_train_id,dtype='uint64')\n",
    "    all_test_pn = np.array(all_test_pn,dtype='int32')\n",
    "    all_test_label = np.array(all_test_label,dtype='int32')\n",
    "    all_test_id = np.array(all_test_id,dtype='uint64')\n",
    "    all_user_pos = np.array(all_user_pos,dtype='int32')\n",
    "    all_test_user_pos = np.array(all_test_user_pos, dtype='int32')\n",
    "\n",
    "    return (userid_dict, user_count, all_train_pn, all_label, all_train_id, all_test_pn, all_test_label, all_test_id, all_user_pos, all_test_user_pos, all_test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "judicial-convention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.5 s, sys: 11.7 ms, total: 4.51 s\n",
      "Wall time: 4.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "userid_dict,user_count, all_train_pn, all_label, all_train_id, all_test_pn, all_test_label, all_test_id, all_user_pos, all_test_user_pos, all_test_index = preprocess_clicked(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beginning-collective",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = (user_count, all_train_pn, all_label, all_train_id, all_test_pn, all_test_label, all_test_id, all_user_pos, all_test_user_pos, all_test_index)\n",
    "\n",
    "file = open('./model/thuytt_ver2/dataloader.pkl', 'wb')\n",
    "pickle.dump(dataloader, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "welcome-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./model/thuytt_ver2/dataloader.pkl', 'rb')\n",
    "user_count, all_train_pn, all_label, all_train_id, all_test_pn, all_test_label, all_test_id, all_user_pos, all_test_user_pos, all_test_index = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-carpet",
   "metadata": {},
   "source": [
    "## Tokenizer and make word_dict of articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "falling-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vncorenlp import VnCoreNLP\n",
    "VnCoreNLP_jar_file = '../vncorenlp/VnCoreNLP-1.1.1.jar'\n",
    "rdrsegmenter = VnCoreNLP(VnCoreNLP_jar_file, annotators='wseg')\n",
    "embedding_dim=768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dangerous-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tôi', 'là', 'sinh_viên', 'trường', 'đại_học', 'Công_nghệ', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdrsegmenter.tokenize('Tôi là sinh viên trường đại học Công nghệ.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "flying-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_news(df):\n",
    "    sapos = df.sapo.values\n",
    "    articleIds = df.articleID.values\n",
    "\n",
    "    news = {} \n",
    "\n",
    "    for i in range(len(articleIds)):\n",
    "        if articleIds[i] not in news:\n",
    "            tokenized_words = rdrsegmenter.tokenize(sapos[i])[0]\n",
    "            news[articleIds[i]] = tokenized_words\n",
    "\n",
    "    \n",
    "    word_dict_raw = {'PADDING': [0,999999]}\n",
    "    for articleId in news:\n",
    "        for word in news[articleId]:\n",
    "            if word in word_dict_raw:\n",
    "                word_dict_raw[word][1] += 1 # increase freq\n",
    "            else:\n",
    "                word_dict_raw[word] = [len(word_dict_raw), 1] # format: [index, freq]\n",
    "                \n",
    "    word_dict = {}\n",
    "    for i in word_dict_raw:\n",
    "        if word_dict_raw[i][1] >= 2:\n",
    "            word_dict[i] = [len(word_dict), word_dict_raw[i][1]]\n",
    "    print('len word_dict (freq>=2 vs raw):', len(word_dict), len(word_dict_raw)) # chỉ để so sánh (loại bỏ freq =1)\n",
    "    \n",
    "    print('leng news (tokenizer):',len(news))\n",
    "\n",
    "    news_words = [ [0]*30 ] # \n",
    "    news_index = {0:0}\n",
    "    \n",
    "    for articleId in news: # quét các article\n",
    "        word_id = []\n",
    "        news_index[articleId] = len(news_index)\n",
    "        for word in news[articleId]: # quét các tokens\n",
    "            if word in word_dict:\n",
    "                word_id.append(word_dict[word][0])\n",
    "        word_id = word_id[:30] # lấy word_id của article (embedd)\n",
    "        news_words.append(word_id + [0]*(30-len(word_id))) # max 30 tokens, <30 cho =0\n",
    "    \n",
    "    news_words = np.array(news_words, dtype='int32')\n",
    "\n",
    "    return word_dict, news_words, news_index, news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "conditional-penguin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len word_dict (freq>=2 vs raw): 3111 7097\n",
      "leng news (tokenizer): 2279\n",
      "CPU times: user 4.81 s, sys: 268 ms, total: 5.07 s\n",
      "Wall time: 8.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_dict, news_words, news_index, news = preprocess_news(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "structured-dictionary",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./model/thuytt_ver2/phobert_news_preprocess.pkl', 'wb')\n",
    "pickle.dump((word_dict, news_words, news_index, news), file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "resident-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./model/thuytt_ver2/phobert_news_preprocess.pkl', 'rb')\n",
    "word_dict, news_words, news_index, news = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-personality",
   "metadata": {},
   "source": [
    "## Phobert + embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "facial-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "# from transformers import RobertaConfig, RobertaModel\n",
    "\n",
    "from fairseq.data.encoders.fastbpe import fastBPE\n",
    "from fairseq.data import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "opposed-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Dictionary()\n",
    "vocab.add_from_file('../PhoBERT_base_transformers/dict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "virtual-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bert model\n",
    "from fairseq.models.roberta import RobertaModel\n",
    "import os\n",
    "phobert = RobertaModel.from_pretrained('../PhoBERT_base_fairseq', checkpoint_file='model.pt')\n",
    "phobert.eval()  # disable dropout (or leave in train mode to finetune)\n",
    "\n",
    "# Incorporate the BPE encoder into PhoBERT-base \n",
    "from fairseq.data.encoders.fastbpe import fastBPE  \n",
    "from fairseq import options  \n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--bpe-codes', \n",
    "    default=\"../PhoBERT_base_transformers/bpe.codes\",\n",
    "    required=False,\n",
    "    type=str,\n",
    "    help='path to fastBPE BPE'\n",
    ")\n",
    "args, unknown = parser.parse_known_args()\n",
    "phobert.bpe = fastBPE(args) #Incorporate the BPE encoder into PhoBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "frequent-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(word_dict):\n",
    "    embedding_dict = {}\n",
    "\n",
    "    for word in word_dict:\n",
    "        input_ids = vocab.encode_line(word, append_eos=False, add_if_not_exist=False).long()\n",
    "        embedding_tensor = phobert.extract_features(input_ids)\n",
    "        embedding_dict[word] = embedding_tensor.data.cpu().numpy()[0][0]\n",
    "        \n",
    "    embedding_matrix = [0]*len(word_dict)\n",
    "    cand = []\n",
    "\n",
    "    for i in embedding_dict:\n",
    "        embedding_matrix[word_dict[i][0]] = np.array(embedding_dict[i], dtype='float32')\n",
    "        cand.append(embedding_matrix[word_dict[i][0]])\n",
    "    \n",
    "    cand = np.array(cand, dtype='float32')\n",
    "    mu = np.mean(cand, axis=0)\n",
    "    Sigma = np.cov(cand.T)\n",
    "    norm = np.random.multivariate_normal(mu, Sigma, 1)\n",
    "\n",
    "    for i in range(len(embedding_matrix)):\n",
    "        if type(embedding_matrix[i]) == int: # unknown words\n",
    "            embedding_matrix[i] = np.reshape(norm, embedding_dim)\n",
    "    \n",
    "    embedding_matrix[0] = np.zeros(embedding_dim, dtype='float32')\n",
    "    embedding_matrix = np.array(embedding_matrix, dtype='float32')\n",
    "\n",
    "    print(embedding_matrix.shape)\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "korean-object",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3111, 768)\n",
      "CPU times: user 32min 14s, sys: 1min 1s, total: 33min 16s\n",
      "Wall time: 1min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedding_mat = get_embedding(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "smart-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./model/thuytt_ver2/phobert_embed_mat.pkl', 'wb')\n",
    "pickle.dump(embedding_mat, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "excess-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('./model/thuytt_ver2/phobert_embed_mat.pkl', 'rb')\n",
    "embedding_mat = pickle.load(file)\n",
    "file.close()\n",
    "embedding_dim=768"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-patent",
   "metadata": {},
   "source": [
    "## Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lightweight-breeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load thuytt_ver2\n",
    "working_dir = '/home/thuytt/test_bert/NCKH/model/thuytt_ver2/'\n",
    "os.chdir(working_dir)\n",
    "\n",
    "file = open('dataloader.pkl', 'rb')\n",
    "user_count, all_train_pn, all_label, all_train_id, all_test_pn, all_test_label, all_test_id, all_user_pos, all_test_user_pos, all_test_index = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('phobert_news_preprocess.pkl', 'rb')\n",
    "word_dict, news_words, news_index, news = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "file = open('phobert_embed_mat.pkl', 'rb')\n",
    "embedding_mat = pickle.load(file)\n",
    "file.close()\n",
    "embedding_dim=768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "historical-secondary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2598, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_user_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "vocal-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_user_pos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-barrier",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supported-office",
   "metadata": {},
   "source": [
    "## Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compound-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(y_true, y_score, k=10):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order[:k])\n",
    "    gains = 2 ** y_true - 1\n",
    "    discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "    return np.sum(gains / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(y_true, y_score, k=10):\n",
    "    best = dcg_score(y_true, y_true, k)\n",
    "    actual = dcg_score(y_true, y_score, k)\n",
    "    return actual / best\n",
    "\n",
    "\n",
    "def mrr_score(y_true, y_score):\n",
    "    order = np.argsort(y_score)[::-1]\n",
    "    y_true = np.take(y_true, order)\n",
    "    rr_score = y_true / (np.arange(len(y_true)) + 1)\n",
    "    return np.sum(rr_score) / np.sum(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "martial-showcase",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _articles_to_index(arr_np):\n",
    "    arr_index_articles = []\n",
    "    for arr_articles in arr_np:\n",
    "        index_article = []\n",
    "        for article in arr_articles:\n",
    "            index_article.append(news_index[article])\n",
    "        arr_index_articles.append(index_article)\n",
    "    arr_index_articles = np.array(arr_index_articles, dtype='int32')\n",
    "    return arr_index_articles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-makeup",
   "metadata": {},
   "source": [
    "## generate batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "valued-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test generate_batch_data_train\n",
    "batch_size = 32\n",
    "inputid = np.arange(len(all_label))\n",
    "np.random.shuffle(inputid)\n",
    "y=all_label\n",
    "batches = [inputid[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "for i in batches:\n",
    "    index_all_train_pn = _articles_to_index(all_train_pn[i])\n",
    "    candidate = news_words[index_all_train_pn]\n",
    "    candidate_split=[candidate[:,k,:] for k in range(candidate.shape[1])]\n",
    "    \n",
    "    #\n",
    "    index_all_user_pos = _articles_to_index(all_user_pos[i])\n",
    "    browsed_news=news_words[index_all_user_pos]\n",
    "    browsed_news_split=[browsed_news[:,k,:] for k in range(browsed_news.shape[1])]\n",
    "    userid=np.expand_dims(all_train_id[i],axis=1)\n",
    "    label=all_label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acknowledged-vintage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_data_train(all_train_pn,all_label,all_train_id,all_user_pos,batch_size):\n",
    "    inputid = np.arange(len(all_label))\n",
    "    np.random.shuffle(inputid)\n",
    "    y=all_label\n",
    "    batches = [inputid[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "\n",
    "    while (True):\n",
    "        for i in batches:\n",
    "            if(i.size ==0):\n",
    "                continue\n",
    "            index_all_train_pn = _articles_to_index(all_train_pn[i])\n",
    "            candidate = news_words[index_all_train_pn]\n",
    "            candidate_split=[candidate[:,k,:] for k in range(candidate.shape[1])]\n",
    "\n",
    "            #\n",
    "            index_all_user_pos = _articles_to_index(all_user_pos[i])\n",
    "            browsed_news=news_words[index_all_user_pos]\n",
    "            browsed_news_split=[browsed_news[:,k,:] for k in range(browsed_news.shape[1])]\n",
    "            userid=np.expand_dims(all_train_id[i],axis=1)\n",
    "            label=all_label[i]\n",
    "            yield (candidate_split +browsed_news_split+[userid], label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wound-quantity",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-1f009afed85d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test generate_batch_data_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minputid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_test_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_test_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minputid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# test generate_batch_data_test\n",
    "inputid = np.arange(len(all_test_label))\n",
    "y=all_test_label\n",
    "batch_size=6\n",
    "batches = [inputid[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "\n",
    "for i in batches:\n",
    "    index_all_test_pn = [news_index[x] for x in all_test_pn[i]]\n",
    "    candidate = news_words[index_all_test_pn]\n",
    "    \n",
    "    tmp = _articles_to_index(all_test_user_pos[i])\n",
    "    browsed_news=news_words[_articles_to_index(all_test_user_pos[i])]\n",
    "    browsed_news_split=[browsed_news[:,k,:] for k in range(browsed_news.shape[1])]\n",
    "    userid=np.expand_dims(all_test_id[i],axis=1)\n",
    "    label=all_test_label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "seven-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_data_test(all_test_pn,all_test_label,all_test_id,all_test_user_pos,batch_size):\n",
    "    inputid = np.arange(len(all_test_label))\n",
    "    y=all_test_label\n",
    "    batches = [inputid[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "\n",
    "    while (True):\n",
    "        for i in batches:\n",
    "            if(i.size ==0):\n",
    "                continue\n",
    "            index_all_test_pn = [news_index[x] for x in all_test_pn[i]]\n",
    "            candidate = news_words[index_all_test_pn]\n",
    "\n",
    "            browsed_news=news_words[_articles_to_index(all_test_user_pos[i])]\n",
    "            browsed_news_split=[browsed_news[:,k,:] for k in range(browsed_news.shape[1])]\n",
    "            userid=np.expand_dims(all_test_id[i],axis=1)\n",
    "            label=all_test_label[i]\n",
    "\n",
    "            yield ([candidate]+ browsed_news_split+[userid], label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-switzerland",
   "metadata": {},
   "source": [
    "## Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "spare-governor",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from keras.optimizers import *\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "impressive-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENT_LENGTH=30\n",
    "MAX_SENTS=50 # maximum clicked news for user embedding\n",
    "npratio=4\n",
    "batch_size=32\n",
    "n_epoch=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "third-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(SEED):\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    tf.compat.v1.set_random_seed(SEED)\n",
    "    \n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "improved-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "\n",
    "\n",
    "# user embedding\n",
    "user_id = Input(shape=(1,), dtype='uint64')\n",
    "\n",
    "user_embedding_layer= Embedding(user_count, MAX_SENTS, trainable=True) #ouput leng == max clicked_news\n",
    "user_embedding= user_embedding_layer(user_id)\n",
    "user_embedding_word= Dense(200,activation='relu')(user_embedding)\n",
    "user_embedding_word= Flatten()(user_embedding_word)\n",
    "user_embedding_news= Dense(200,activation='relu')(user_embedding)\n",
    "user_embedding_news= Flatten()(user_embedding_news)\n",
    "\n",
    "\n",
    "# news embedding architecture\n",
    "news_input = Input(shape=(MAX_SENT_LENGTH,), dtype='k')\n",
    "embedding_layer = Embedding(len(word_dict) , embedding_dim, weights=[embedding_mat],trainable=True)\n",
    "embedded_sequences = embedding_layer(news_input)\n",
    "embedded_sequences =Dropout(0.2)(embedded_sequences)\n",
    "\n",
    "cnnouput = Conv1D(padding='same', activation='relu', strides=1, filters=embedding_dim, kernel_size=3)(embedded_sequences)\n",
    "cnnouput=Dropout(0.2)(cnnouput)\n",
    "\n",
    "attention_a = Dot((2, 1))([cnnouput, Dense(embedding_dim,activation='tanh')(user_embedding_word)])\n",
    "attention_weight = Activation('softmax')(attention_a)\n",
    "news_rep=keras.layers.Dot((1, 1))([cnnouput, attention_weight])\n",
    "newsEncoder = Model([news_input,user_id], news_rep)\n",
    "\n",
    "\n",
    "# clicked news embedding\n",
    "all_news_input = [keras.Input((MAX_SENT_LENGTH,), dtype='int32') for _ in range(MAX_SENTS)]\n",
    "browsed_news_rep = [newsEncoder([news,user_id]) for news in all_news_input]\n",
    "browsed_news_rep = concatenate([Lambda(lambda x: K.expand_dims(x,axis=1))(news) for news in browsed_news_rep],axis=1)\n",
    "\n",
    "\n",
    "# User Embedding\n",
    "attention_news = keras.layers.Dot((2, 1))([browsed_news_rep, Dense(embedding_dim,activation='tanh')(user_embedding_news)])\n",
    "attention_weight_news = Activation('softmax')(attention_news)\n",
    "user_rep=keras.layers.Dot((1, 1))([browsed_news_rep, attention_weight_news])\n",
    "\n",
    "\n",
    "# candidate news embedding\n",
    "candidates = [keras.Input((MAX_SENT_LENGTH,), dtype='int32') for _ in range(1+npratio)]\n",
    "candidate_vecs = [ newsEncoder([candidate,user_id]) for candidate in candidates]\n",
    "\n",
    "# Click Predictor???\n",
    "logits = [keras.layers.dot([user_rep, candidate_vec], axes=-1) for candidate_vec in candidate_vecs]\n",
    "logits = keras.layers.Activation(keras.activations.softmax)(keras.layers.concatenate(logits))\n",
    "\n",
    "\n",
    "model = Model(candidates+all_news_input+[user_id], logits)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.00025), metrics=['acc'])\n",
    "\n",
    "\n",
    "candidate_one = keras.Input((MAX_SENT_LENGTH,))\n",
    "candidate_one_vec = newsEncoder([candidate_one,user_id])\n",
    "score = keras.layers.Activation(keras.activations.sigmoid)(keras.layers.dot([user_rep, candidate_one_vec], axes=-1))\n",
    "model_test = keras.Model([candidate_one]+all_news_input+[user_id], score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "naval-district",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_7 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_15 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_17 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_19 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_23 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_25 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_27 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_29 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_31 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_33 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_35 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_37 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_39 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_41 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_43 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_45 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_47 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_49 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_51 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_52 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 50)        950         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 768)          4325006     input_3[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_5[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_6[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_7[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_9[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_11[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_12[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_13[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_14[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_15[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_16[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_17[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_18[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_19[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_20[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_21[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_22[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_23[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_24[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_25[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_26[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_27[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_28[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_29[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_30[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_31[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_32[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_33[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_34[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_35[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_36[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_37[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_38[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_39[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_40[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_41[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_42[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_43[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_44[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_45[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_46[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_47[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_48[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_49[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_50[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_51[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_52[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_53[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_54[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_55[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_56[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_57[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1, 200)       10200       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 768)       0           model_1[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 1, 768)       0           model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 1, 768)       0           model_1[3][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1, 768)       0           model_1[4][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 768)       0           model_1[5][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1, 768)       0           model_1[6][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1, 768)       0           model_1[7][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 1, 768)       0           model_1[8][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1, 768)       0           model_1[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1, 768)       0           model_1[10][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1, 768)       0           model_1[11][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1, 768)       0           model_1[12][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 1, 768)       0           model_1[13][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1, 768)       0           model_1[14][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1, 768)       0           model_1[15][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 1, 768)       0           model_1[16][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1, 768)       0           model_1[17][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1, 768)       0           model_1[18][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 1, 768)       0           model_1[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 1, 768)       0           model_1[20][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 1, 768)       0           model_1[21][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 1, 768)       0           model_1[22][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1, 768)       0           model_1[23][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1, 768)       0           model_1[24][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 1, 768)       0           model_1[25][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 1, 768)       0           model_1[26][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 1, 768)       0           model_1[27][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 1, 768)       0           model_1[28][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1, 768)       0           model_1[29][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1, 768)       0           model_1[30][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 1, 768)       0           model_1[31][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 1, 768)       0           model_1[32][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 1, 768)       0           model_1[33][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 1, 768)       0           model_1[34][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 1, 768)       0           model_1[35][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 1, 768)       0           model_1[36][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 1, 768)       0           model_1[37][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 1, 768)       0           model_1[38][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 1, 768)       0           model_1[39][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 1, 768)       0           model_1[40][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 1, 768)       0           model_1[41][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 1, 768)       0           model_1[42][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 1, 768)       0           model_1[43][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 1, 768)       0           model_1[44][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 1, 768)       0           model_1[45][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 1, 768)       0           model_1[46][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 1, 768)       0           model_1[47][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 1, 768)       0           model_1[48][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 1, 768)       0           model_1[49][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 1, 768)       0           model_1[50][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 200)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 50, 768)      0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "                                                                 lambda_20[0][0]                  \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 lambda_22[0][0]                  \n",
      "                                                                 lambda_23[0][0]                  \n",
      "                                                                 lambda_24[0][0]                  \n",
      "                                                                 lambda_25[0][0]                  \n",
      "                                                                 lambda_26[0][0]                  \n",
      "                                                                 lambda_27[0][0]                  \n",
      "                                                                 lambda_28[0][0]                  \n",
      "                                                                 lambda_29[0][0]                  \n",
      "                                                                 lambda_30[0][0]                  \n",
      "                                                                 lambda_31[0][0]                  \n",
      "                                                                 lambda_32[0][0]                  \n",
      "                                                                 lambda_33[0][0]                  \n",
      "                                                                 lambda_34[0][0]                  \n",
      "                                                                 lambda_35[0][0]                  \n",
      "                                                                 lambda_36[0][0]                  \n",
      "                                                                 lambda_37[0][0]                  \n",
      "                                                                 lambda_38[0][0]                  \n",
      "                                                                 lambda_39[0][0]                  \n",
      "                                                                 lambda_40[0][0]                  \n",
      "                                                                 lambda_41[0][0]                  \n",
      "                                                                 lambda_42[0][0]                  \n",
      "                                                                 lambda_43[0][0]                  \n",
      "                                                                 lambda_44[0][0]                  \n",
      "                                                                 lambda_45[0][0]                  \n",
      "                                                                 lambda_46[0][0]                  \n",
      "                                                                 lambda_47[0][0]                  \n",
      "                                                                 lambda_48[0][0]                  \n",
      "                                                                 lambda_49[0][0]                  \n",
      "                                                                 lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 768)          154368      flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dot_3 (Dot)                     (None, 50)           0           concatenate_1[0][0]              \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 50)           0           dot_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_53 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_55 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_56 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_57 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dot_4 (Dot)                     (None, 768)          0           concatenate_1[0][0]              \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dot_5 (Dot)                     (None, 1)            0           dot_4[0][0]                      \n",
      "                                                                 model_1[51][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_6 (Dot)                     (None, 1)            0           dot_4[0][0]                      \n",
      "                                                                 model_1[52][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_7 (Dot)                     (None, 1)            0           dot_4[0][0]                      \n",
      "                                                                 model_1[53][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_8 (Dot)                     (None, 1)            0           dot_4[0][0]                      \n",
      "                                                                 model_1[54][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_9 (Dot)                     (None, 1)            0           dot_4[0][0]                      \n",
      "                                                                 model_1[55][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5)            0           dot_5[0][0]                      \n",
      "                                                                 dot_6[0][0]                      \n",
      "                                                                 dot_7[0][0]                      \n",
      "                                                                 dot_8[0][0]                      \n",
      "                                                                 dot_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 5)            0           concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 4,489,574\n",
      "Trainable params: 4,489,574\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "banned-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputid = np.arange(len(all_test_label))\n",
    "y=all_test_label\n",
    "batch_size=100\n",
    "batches = [inputid[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "# print(batches)\n",
    "\n",
    "for i in batches:\n",
    "    if(i.size ==0):\n",
    "        continue\n",
    "    index_all_test_pn = [news_index[x] for x in all_test_pn[i]]\n",
    "    candidate = news_words[index_all_test_pn]\n",
    "\n",
    "    browsed_news=news_words[_articles_to_index(all_test_user_pos[i])]\n",
    "    browsed_news_split=[browsed_news[:,k,:] for k in range(browsed_news.shape[1])]\n",
    "    userid=np.expand_dims(all_test_id[i],axis=1)\n",
    "    label=all_test_label[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "incorrect-annex",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95, 30)\n",
      "50\n",
      "(95, 50, 30)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71\n",
      " 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 366,  367,  204, ...,    0,    0,    0],\n",
       "       [ 366,  367,  204, ...,    0,    0,    0],\n",
       "       [ 366,  367,  204, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [2473,  296,   38, ...,    0,    0,    0],\n",
       "       [2473,  296,   38, ...,    0,    0,    0],\n",
       "       [2473,  296,   38, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(browsed_news_split[0].shape)\n",
    "print(len(browsed_news_split))\n",
    "print(browsed_news.shape)\n",
    "print(batches[0])\n",
    "browsed_news_split[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "exposed-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  15 2448  584 1328 2345    8 2415 1633    2 1908 1498 2425  606  761\n",
      "  129  778  228  884  341 1009 2261 2408 2364  825 1882 1133 2124 2521\n",
      " 1217 1851 1586 2144 1569 1694 2318 1182 1450 2055 2188  434 2140  166\n",
      " 1919 2192 2447 1784  649 1465   34 1464 1527 1726 1889  669 1421 2270\n",
      " 1933 2285 2187  863  776 1347 2111 2122 2074   98 2386 2368 2269   50\n",
      " 1879  112 1302 1249  190 1966  200 1669  941  868  621 1474  543 2566\n",
      " 1881    6 2171  998 1378 1045 1135 1068 2359 2350  484 1103  694  957\n",
      " 1481 1778]\n",
      "[1535 2339  164 1468 2580  155 1764  174  798 1487 1544 2556 1444  466\n",
      " 1979  435 2342 1235  388 2248 1855 1070 2541 1094 1159  842 1136  978\n",
      " 1360 2575 1111 1309  807 2589 1695  331  726  795    1 2097  461 1529\n",
      " 2532 1300  492  302 1453  206 1040  512  975 1197  883 1073 2467  749\n",
      " 2578  233 2087 2010  305 1252 1559 2510 2139 2059 2597 1256 1191 2189\n",
      " 1396 2117 2041 1654 1290 2115 1429  121  712 1575 2070   84 1000  722\n",
      "  561 1166  517 1840  973 2217 1198  494  697 1348 1162  324  165 1839\n",
      "  405 1115]\n",
      "[2411 1954  201 2160 1848 1736 1170  501 1894  551 2032  450   46 1412\n",
      " 1711 2161 1925 1274 1870  881 1143 1665 1054 1327 2040 2174 1962  844\n",
      " 1955  149  459 1129 2206 2000  808 1763 2327 2066 1323  182 1917  246\n",
      "  917   28  890  137 1488  908 2277 1614 1967  568  315  681 2534 1834\n",
      "  772 1783 1555 2446 1192 1989  905  767 1856 2260  487 1547  167 1280\n",
      " 2173  527 2013 1923  463 2241 1712 2108 1150 1212 1587 2136 1272 1404\n",
      " 2272 2330 2461   73 2067  872  475  455 1482  378 1062 1241  115  670\n",
      "  573  432]\n",
      "[2163 1278 1651 2587  188  284 1660 1185 2376 1795   10  387 2459 2547\n",
      " 2420 1149 2484  486  476 2159  258 1511  951 1755  980  946   43  797\n",
      " 1739  367  939 1745 2374  227  705 2365 1376  452 1320  202 2158 2191\n",
      "  955 2450  607   60 1516 2123 2401  707 1307 2031 1273  587 2317 1340\n",
      "  673  327 1863   26  609  699 2561   81 1104 1478  655  152  742  399\n",
      " 1802  328 1891 2497 2083 1336 2043   51 2178 1717  871 2072 2584 1216\n",
      " 1213   27  506  805 1686 1746  312 2582 2540 1576  880 1157  867 1613\n",
      " 1078 1566]\n",
      "[ 622  672 1492 1531 1946  931 1725  325  923 1675   87 2112 1167 1051\n",
      " 1485 1902 1334  794 2121  696 1113  384 1153 1501 1147 1996  423 2303\n",
      " 2301 1285 1449  554 1618  474 1188    5 2225 1710 1747   38 2004 1379\n",
      "  219  393 1380 1750 1194 1731  986   90 1937 1832 1595  569 1608  578\n",
      "  600 1781  192 1121 1417  788  982  268 1699 2520 1796 1992  222 1584\n",
      "  292  768 1770  819 2398  226 1475 1987 2044 1022 1019  985 1483 2091\n",
      " 2553  363 2086  410 1141 1422  436 1239  860 2005  382  300  853  358\n",
      "  708 2281]\n",
      "[1343  813  929  267 1986 1386   79  122  125 1134  181  116 1186  138\n",
      " 2332 1701 1630 2237  370 2073  296  897 2309  961 1205  126 1037  354\n",
      "  658 2036 1850  100 1773 1106 1071  962 1033  839 2469 1496 1853 2562\n",
      "  203 1858 1446 1262 1391 2464 2037  293  308  684 1375 2009 1358 2550\n",
      "  409 1065 1508 1424  299   64  812 1727 2129  218  298  380 1805 1363\n",
      "  247  437  356  564 1714 2392 1298 1036  915 1467 1171 1550 2592 2414\n",
      "  960 2182 2493 1700  229  425 1632 1525 1377  232  989 2352  715 1055\n",
      "  281   97]\n",
      "[ 926 2274  740   74  170  893 1892  383  490 1173 1105 1772 1643   25\n",
      " 2435  595  456  280  824 2002 1846 2384 2479  854 1757 2145  135  376\n",
      "   78 1457 1294 1638  239 1752 1991 2060  690 2428 1200 1345 1645  971\n",
      " 2466 1546 2052 1678 2113 1493  877 2431  156  525   47  582 1950 1287\n",
      " 1231  109  685  306 1389  449 1837  333 2531   80  972 2432 1303  559\n",
      "   71  290 1573 1199 2517 2485 1414  288 1398 2422  151  650  297  937\n",
      " 2378 1006 2020 1031 1080 2440 2379 1075  556  930 2338 1439 1445 1760\n",
      "   56  835]\n",
      "[1168  309  886  541 1815 2515 1016 2452  406 2482  442 2402   22  639\n",
      " 1932  604   91  171  916 2449 1600 1812  633 2504  703 2372 2102  596\n",
      "  698 1050 1912 1585  366  549 2201 2252  616 1603 1758 2487 1872   17\n",
      " 2295 1338 1868  732 1861 2089 1624 2567  774 2116 2259 2283 2232  645\n",
      "  944  940 1538 1681  754 1537  236 1504  500 1968  689  447 1322 1788\n",
      " 1708 1617 1821 1728  656 1420 1069  857 1524  526  357 1399  340 1454\n",
      " 1655 1089   62  132  230  242 1611  101 1208 1507 1607 1612  947 2034\n",
      "  850  629]\n",
      "[1244 1271 2204 1823 1873 1281 1209 1539 2075 2335 2514  605  575  902\n",
      "  540  727 1282  677 1647 1822  528  552 1977  787  183  925  680 1058\n",
      " 1056  983   95  243 1039  139 1430   31 2351 2127  553  277  714  448\n",
      "  935  472 2186 2399   94 1260 1394 2463 1572 1599  741  921  594   19\n",
      " 1427  515  999 2071 1095 1565  683 1021  523 1589  394 2311 2023 1737\n",
      "  814  598 1857 1580  615 2014 2282 2183 1642  682  571  330 2131 1267\n",
      "  544  637 2512 1032  913  557  765  919 1656  143  660 2051 1357 1552\n",
      " 2038  294]\n",
      "[2226  630 2353  272  777 1640 1751 1545  462  763  706  583  608 1994\n",
      " 2424  114  984 2119  467 1023 1119 2397   14 1958  250  413 2593  981\n",
      " 2395 2085 1896  783 1438 1277  723 1242 2056 1970 1411 2265  762 1753\n",
      "  429  234 1976 2511  912  441  329 2346 1313 1371   24  279  945  287\n",
      " 1756  845 1299  291 1316  375 1184 2264 1288  566 2198 2280  210 1771\n",
      " 1523 1284 1015 1886 2181  548 2518  739 1164 1335 1028 1126 2003  338\n",
      " 1083 1330 2499  458  970  565 1679   52 1988 1998  896 1441 1820  864\n",
      " 1469 1428]\n",
      "[2046 1554  108 1592 1898 1489   83  102  351  891 1561  140 2486 2058\n",
      "  593 2256  473  433   75 1324  419 2439  725 1112 1661 1984  950 1434\n",
      "  760 2377  653 1195 2548   99  460 1765 1903 1921  255 1463 2195 1084\n",
      " 1558 2524 1680  514   89 2319  360  217 1138 2468   18  759 2406  711\n",
      " 1844 1748  678  295  731  175 2546  117  310 2222  530 2079 2483   86\n",
      " 1494 1972 1835  283 1646 2045 2554  120 1884 1597 2048 2380 1295 2029\n",
      "  545 2552 1951  103 1594 2063  887 1233 1774 2231 1456  209  146 1125\n",
      " 1676  847]\n",
      "[2477 2307  634 1847 2184 1583 1179 2104  675  180 2068  654  801 1433\n",
      "  276 1372  625 2254 1144 1581  178  692 1072 2042  348 1010  987  953\n",
      " 1616 1502  848 1097 1471  397 1785 1064  147  786   68 2223  496 2413\n",
      " 2576 1258 2142 2394  992 1875 2054 1911 1026 1352 1831  411 1131 1944\n",
      " 2400 1689 1367 2492 2240 1219 1671  856 2502 2457  223 1667 1236  420\n",
      "  415   82 1869 1099  207 1178 2478 2558 2437 1663 2137  859  855 1477\n",
      "   63 2157 2050  828  836 2583 2334 2393  274  335  748   55   72  642\n",
      "  746 1264]\n",
      "[ 799 1703 1564 1128  495 2267  332 2100  381  355 1571  563 2416 1653\n",
      " 1110 1841  610 2436 2453 1677  818  879 2134  314 2208 1289  820  920\n",
      "  858 2535  809  519 1588 1515 2263  826 1985 1161  567  889  518  979\n",
      "  224  632 1652  275 1768 1014 2573 1275 2381 1029  172 2455 2257  974\n",
      "  558 1859 1382  646 2081 2341  904 1813 1387 1540 1416 1930 1928 1384\n",
      "  118 1683 1791  390 1337 2262 1621 2218 1664 1432 2118 1769 1741   20\n",
      " 2021 1920  546   32  428  938 1344 1862 2227 2555  743  769 1659 1265\n",
      " 1743 1354]\n",
      "[ 652  481  590  231 1629 2390 1720 1237  834  529 2404  249 2569 1495\n",
      "  823  513  831 1657  841 1120  477  693 2383  851 1366  257 1767 1914\n",
      " 2325  491  470  988 1005  811  613  124 2196 1974 1472 2356  830 2501\n",
      " 1220  440 2305  663  252  377  194  906  907  977  719 1793   35 2336\n",
      "  159 2559 1799 1373 1405 1553  753 1176 1118  539  504  586   65 2438\n",
      "  451 1964 2588 2329 1407 1649 1754 1590 1117  796 2360 1893  531 1155\n",
      " 1721    0 1591 2591  875 2316 1350  505 2403  469  362  141  485 1691\n",
      " 2209 2148]\n",
      "[1254 1049 2549 1437  735 1151 2028  628  900  943 1400 1959  750  717\n",
      " 1451  671 1854 1279  661  892  936 2344 1843  349  648 2006 1707 1519\n",
      "  659  313 2545 2441 1025 1522 1596 2496  662 2210  771 1662 1132  336\n",
      " 1543 1257 2306 2465 2125 1698  421 1956 1797 1470 2315 2445 1949  237\n",
      " 1304   30 1582 1007 1533 2391 1499   77 1838 2361  770  766 2522  493\n",
      " 1713 1512 1803 1223 1190  211 2568 2156  709 2242 2572 2433 2294  756\n",
      " 1063 1557 2022  153  119  968 2563 1114 1965  579 2062  581  398  304\n",
      " 2094  667]\n",
      "[1735 1202 1415 1158  365 1096 1455  148 2475  736  199  254 2233 1530\n",
      "  307 2571 1460 1626 2495  626  688  810 1248 1458 1497 1742 1163  990\n",
      " 1999 2185 2434 1419  910  317 1052 1059 1801  755  641 1426  162  503\n",
      " 1152 2472 1715   85 1780 1124  263 1798  840 1018 1816  285 2212 1418\n",
      " 2027 1383 2025  508 2082  624 1187 1729 2092  603 1759  701  898  866\n",
      "  453   76  465  849 1448  976 1098 1674 1310 1165  821 1100 2488 1941\n",
      " 1789  822  618 1644 1102 1927 1969 1314  163    9  113 1563 2172 1880\n",
      " 1017 2154]\n",
      "[1622   23 2197 2526  270    7  758  861 1782 2523 2595 1130 1929 2101\n",
      " 1234  161 1790 2462 2165 2103 1860  412 2150 1961 2273 2560  535 1628\n",
      " 2133 2530 1878  852 1189 2138  438 1560  248  751 1013 1943 1090 1088\n",
      " 1845 1085 1116 2442 2164 1865 1541 1390 2507  321  289 1034  260 2471\n",
      " 1883   59  547 2304 2430  888  235 1733 2594 1593  827  318   16  878\n",
      "  730 1935  160 1817 1852 2357 1318 2412  253  110 1926  403 1794  195\n",
      "  679 2500  106 2458  785  123  345  422  580 1484  316 1940 1620 2180\n",
      "  964 2299]\n",
      "[1825  899 1895 1046 2239 1108 2506 2236 1361 1786 2078  687  507 2385\n",
      "  764  757  869 2096 1548 1227  216  969   69 1625 2088 1461  817 2409\n",
      "  154  932 1631 1526 2590  720  392 2574 1362 2193  534 1634 2017  666\n",
      " 1283 2179 1792 2528  391 2362 1957 1568 1990 1779  186 1074  537 2292\n",
      "  158 2508 1971 1627 2473  342 1687 1174 1002 1922  664 2194 2001 2190\n",
      " 2454  400  918 2444 1716 1693 2503  386 1160 2126  107 1374  361 1349\n",
      " 1513 1830 2152 1308 1685 1899  424  803 1326 2135  870  134  197  368\n",
      " 2268 2474]\n",
      "[2147  737 1479 1462 2366 1909  142 2347 2310 2016 1960 1924  221 1425\n",
      " 1269  271  212 2266 1311 1057 1697  611 1436 2207 1012  225 2527  427\n",
      "  954 1945  555  169 1297 1606 1238 2199 1690  874 2234   67  339  627\n",
      " 1814 1636 1053  815  721  443 1521 2387  724  350 1915 1240  347  521\n",
      "  676 2019 1877 1995  718  538  177 2324  187 2405  577  524 2490 1368\n",
      " 2308 2011  532 2276  320  407  585 1953 1828 1107 2410 2421 1682  792\n",
      " 1137  948  804 1518 1983 2382 1353  713 2106 2177 1123  695 1609 1948\n",
      " 1402    3]\n",
      "[1296  966 1567  238 1491 1740  934 1196 1648 2151 2065 1978 2516 1601\n",
      " 1672 1222 2525  597 1579 1246  457  922 1673 2551  674 1381 1266 1086\n",
      " 1263 2513 1724  185 2354 1542 1574 1317  395 1061  414 2155 2221 2289\n",
      "  193  127  647   37 2328 2570 1193 2443 1041   21 1702 2481  862 1811\n",
      " 2099 1934  352 1738 1973 2018  644 2371  846 2251  337 1148  651 2214\n",
      " 1211   13 2494 1826 1225  262 2069 2061 1692  958 1339 2286 1268 1473\n",
      "  631 1253 1658   12  894 1312 2533 1395 1761 2557 1916  816 2200  601\n",
      " 1936  773]\n",
      "[ 570  444 1385  744 1500 1351  344 1342 2220 2320 1201 1570 1605 1047\n",
      " 1562 1506  745  909   11 1122 2519 1684 2370 1044 2095   48 1440 2542\n",
      " 1762  959 1556  914 1809 1905   49  179   45 1602 1388  176  716 1207\n",
      " 1906  261 2451  729 1008 1641 1156 1514  614 2141 1829 1819  700 2279\n",
      "  346 1048  364 2529  240 2205  431 2149  775 1423 1092   96  374  592\n",
      " 1319   88 2460 1401 1393 1775 2278  911  319 1331 2476  942  401  372\n",
      "   36 2143 2321 1203  838 2418 2375  802 1842  396 1321 1551 2423  511\n",
      " 1744  617]\n",
      "[1913  793 1766  205  278 1833  220  991 1406 2230  965  612 2039  256\n",
      "  326  738 2228 1907 1505 1650 2284  379 1293  480 1043 1623 1229 1226\n",
      " 1997 1081 2110 1146 1749 1245  895 1888 1093  198  686 1578 1077 1993\n",
      " 1719  599  343  168  417   53 2166 2470 1447 2296 2213  572   39  560\n",
      "  591   93 1706 2246 1230   40 2291 1403 1180  995 1885 2114 2498 2064\n",
      " 1251  643 1001 2244  215  784 1466 2348  478 2369  640 1306 2077  265\n",
      "  843 2358  499 2505  710 2349 1528 1668 1270  509 2076   29   92 2298\n",
      " 1604 2219]\n",
      "[1341 1777  251 1228 1619 2255  418 2509 1204  468  196   41 1901  241\n",
      " 1459 1704 2419  588 1807  952  665 1276 2333 2302 2238 1918  704 1824\n",
      " 1476  150 2331 1181 2215 1301 1610 1369 2543 2312 2224 1688  105 1947\n",
      "  876 2343    4 2024 2544 2491 2176 2035 1042 2579  882 1431  956 2367\n",
      " 1030  800 1109 2084 1532  286   61  144 1175 1142 1867  927   33  128\n",
      "  282 1696  245 1818  111 1509  752  189  602 2480  562  829 1938 2389\n",
      " 1101 1871  522  439  806 1975  323 1849 1435  385 1020  780 1356 1392\n",
      "  498  131]\n",
      "[1942  259 2536  691 2128 2564  510 2426 2323  782 1091  213 1183 1810\n",
      " 2288  373  430 1534 2287 2107 2581 2355  789 1060 1127 2007 1510 2417\n",
      "  454   54 1333 1904 2253 2596 2322 1939  389   57 1776 1804  901  471\n",
      " 1503  657 1067  837 1370 1255 2297 1800  993  273 1365  833 2363  269\n",
      "  497 1517 2211   42 2313 2586 2167 1325 1598 2109  779 1980 1305  589\n",
      " 2015 1409 1808 2170  873  464 2008 2098 2229  404 2585 1806 1480 2337\n",
      " 1261  145 1635  311 2300 1218 2456  402 2090 1087   66 1910 2565 2340\n",
      " 1140 1890]\n",
      "[2326  334 2049 1982 1897 1864 1442 1615  488 1722 1577  416  322 2388\n",
      " 1549 1329  204 1076 1004 2057   44 1079 1259 1169  832  408 1139 1723\n",
      "  426 2168 1827 2162 2053  516  536  949  576 1876 1082  933 2314 2080\n",
      " 2396 2275  482 1952 2290 2235 2093  191  638  244 1413  136  636 1718\n",
      " 1247 1291  264   58  184 2538 2258 1981  353 1963 2153 1410 1836  550\n",
      "  489 1364 2577 2245  702  885 2105  574 2216 2539 2243  619  728 1221\n",
      "  157 1172 2132 2175  483 2247 1866  520  747 1408 1066  208 1486 1011\n",
      " 1177 1038]\n",
      "[ 996 1224 1206 2026  445 2202 1359  734  903  997 1666 1443  266 1705\n",
      "  623 1210  133 2203 1490  928  214 1520 1154 1355  371 1243 2427 1787\n",
      " 1734  479  502  104  781 2130 2407 1732 1214 2293 1024  130  369 2047\n",
      " 1900  359 1286 1145 2169 2489  924  994 1874 2033 2249  668  620 1292\n",
      " 2120 1027 1670 2373  967  963  865  303  533 2146  301  542 1637 1315\n",
      " 1452  791 1730 1035 1931 1232  790 1215  173 2012 2030 1536 1709 2250\n",
      "   70 2537 1003 1887 1346 1250  446 1332 1639 2271  733  635 1397 2429]\n"
     ]
    }
   ],
   "source": [
    "# test generate_batch_data_train\n",
    "batch_size = 100\n",
    "inputid = np.arange(len(all_label))\n",
    "np.random.shuffle(inputid)\n",
    "y=all_label\n",
    "batches = [inputid[range(batch_size*i, min(len(y), batch_size*(i+1)))] for i in range(len(y)//batch_size+1)]\n",
    "for i in batches:\n",
    "    index_all_train_pn = _articles_to_index(all_train_pn[i])\n",
    "    candidate = news_words[index_all_train_pn]\n",
    "    candidate_split=[candidate[:,k,:] for k in range(candidate.shape[1])]\n",
    "    \n",
    "    #\n",
    "    index_all_user_pos = _articles_to_index(all_user_pos[i])\n",
    "    browsed_news=news_words[index_all_user_pos]\n",
    "    browsed_news_split=[browsed_news[:,k,:] for k in range(browsed_news.shape[1])]\n",
    "    userid=np.expand_dims(all_train_id[i],axis=1)\n",
    "    label=all_label[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "valid-softball",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2598\n",
      "2598\n",
      "2598\n",
      "(98, 30)\n",
      "50\n",
      "(98, 50, 30)\n",
      "26\n",
      "[  15 2448  584 1328 2345    8 2415 1633    2 1908 1498 2425  606  761\n",
      "  129  778  228  884  341 1009 2261 2408 2364  825 1882 1133 2124 2521\n",
      " 1217 1851 1586 2144 1569 1694 2318 1182 1450 2055 2188  434 2140  166\n",
      " 1919 2192 2447 1784  649 1465   34 1464 1527 1726 1889  669 1421 2270\n",
      " 1933 2285 2187  863  776 1347 2111 2122 2074   98 2386 2368 2269   50\n",
      " 1879  112 1302 1249  190 1966  200 1669  941  868  621 1474  543 2566\n",
      " 1881    6 2171  998 1378 1045 1135 1068 2359 2350  484 1103  694  957\n",
      " 1481 1778]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  97,    4,   29, ...,    0,    0,    0],\n",
       "       [   4,  110,   61, ...,    0,    0,    0],\n",
       "       [1681,  533,   24, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 158,    0,    0, ...,    0,    0,    0],\n",
       "       [ 171,  172,    0, ...,    0,    0,    0],\n",
       "       [2133, 1564,  344, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 513,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(y))\n",
    "print(len(all_user_pos))\n",
    "print(len(all_train_pn))\n",
    "print(browsed_news_split[0].shape)\n",
    "print(len(browsed_news_split))\n",
    "print(browsed_news.shape)\n",
    "print(len(batches))\n",
    "print((batches[0]))\n",
    "browsed_news_split[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "collectible-poster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 1)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "protecting-fellowship",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'assign'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/phobert/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_truncate_execution_to_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_truncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'assign'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-8d616f9def4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtestgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_batch_data_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_test_pn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_test_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_test_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_test_user_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclick_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestgen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_test_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/phobert/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1906\u001b[0m                   \u001b[0;34m'will be removed in a future version. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m                   'Please use `Model.predict`, which supports generators.')\n\u001b[0;32m-> 1908\u001b[0;31m     return self.predict(\n\u001b[0m\u001b[1;32m   1909\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/phobert/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1623\u001b[0m       \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1624\u001b[0m       \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1625\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1626\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/phobert/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1130\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/phobert/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/phobert/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_truncate_execution_to_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_truncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'assign'"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "testgen=generate_batch_data_test(all_test_pn, all_test_label, all_test_id, all_test_user_pos, batch_size)\n",
    "click_score = model_test.predict_generator(testgen, steps=len(all_test_id)//batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "forward-strike",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sapo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1002681074</td>\n",
       "      <td>4102465</td>\n",
       "      <td>Mi Smart Compact Projector hỗ trợ kích thước t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid  articleID                                               sapo\n",
       "64  1002681074    4102465  Mi Smart Compact Projector hỗ trợ kích thước t..."
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_rec = all_test_pn[click_score.argmax()]\n",
    "df[df.articleID== news_rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "loving-debate",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95, 50)"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_pn.shape\n",
    "all_test_user_pos.shape\n",
    "# all_test_label[0:5]\n",
    "# all_test_id[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "bridal-portugal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1002681074: 0,\n",
       " 1027182531: 1,\n",
       " 1004465291: 2,\n",
       " 1045106859: 3,\n",
       " 1039533691: 4,\n",
       " 1065193564: 5,\n",
       " 1065294702: 6,\n",
       " 1044039998: 7,\n",
       " 1007658224: 8,\n",
       " 1039926550: 9,\n",
       " 1005981237: 10,\n",
       " 1054047771: 11,\n",
       " 1061488042: 12,\n",
       " 1002624136: 13,\n",
       " 1062874128: 14,\n",
       " 1049360283: 15,\n",
       " 1026748786: 16,\n",
       " 1013734256: 17,\n",
       " 1003347668: 18}"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "simplified-chance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4102465"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_test_pn[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "metropolitan-hollow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sapo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4243840</td>\n",
       "      <td>Mohamed Salah liên tục lắc đầu và tỏ vẻ ngán n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4243738</td>\n",
       "      <td>Liverpool là đội vô địch đầu tiên thua liền nă...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4243397</td>\n",
       "      <td>Theo tay vợt số hai thế giới Rafael Nadal, phá...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4243189</td>\n",
       "      <td>Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4242602</td>\n",
       "      <td>HLV Ronald Koeman muốn gia hạn hợp đồng với Ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2085</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4135545</td>\n",
       "      <td>HLV Liverpool Jurgen Klopp tuyên bố đứng ngoài...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4135545</td>\n",
       "      <td>HLV Liverpool Jurgen Klopp tuyên bố đứng ngoài...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2093</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4135808</td>\n",
       "      <td>HLV Jurgen Klopp bất bình khi đồng nghiệp bên ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4135810</td>\n",
       "      <td>Ngoại hạng Anh mùa 2020-2021 bắt đầu từ ngày 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2100</th>\n",
       "      <td>1027182531</td>\n",
       "      <td>4137670</td>\n",
       "      <td>Mariano Diaz bị gạt khỏi kế hoạch chuẩn bị cho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>581 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             uid  articleID                                               sapo\n",
       "65    1027182531    4243840  Mohamed Salah liên tục lắc đầu và tỏ vẻ ngán n...\n",
       "66    1027182531    4243738  Liverpool là đội vô địch đầu tiên thua liền nă...\n",
       "67    1027182531    4243397  Theo tay vợt số hai thế giới Rafael Nadal, phá...\n",
       "68    1027182531    4243189                                           Scotland\n",
       "69    1027182531    4242602  HLV Ronald Koeman muốn gia hạn hợp đồng với Ba...\n",
       "...          ...        ...                                                ...\n",
       "2085  1027182531    4135545  HLV Liverpool Jurgen Klopp tuyên bố đứng ngoài...\n",
       "2086  1027182531    4135545  HLV Liverpool Jurgen Klopp tuyên bố đứng ngoài...\n",
       "2093  1027182531    4135808  HLV Jurgen Klopp bất bình khi đồng nghiệp bên ...\n",
       "2094  1027182531    4135810  Ngoại hạng Anh mùa 2020-2021 bắt đầu từ ngày 1...\n",
       "2100  1027182531    4137670  Mariano Diaz bị gạt khỏi kế hoạch chuẩn bị cho...\n",
       "\n",
       "[581 rows x 3 columns]"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df.uid==1027182531)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "recognized-drilling",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>articleID</th>\n",
       "      <th>sapo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1002681074</td>\n",
       "      <td>4102465</td>\n",
       "      <td>Mi Smart Compact Projector hỗ trợ kích thước t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           uid  articleID                                               sapo\n",
       "64  1002681074    4102465  Mi Smart Compact Projector hỗ trợ kích thước t..."
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.articleID == all_test_pn[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "isolated-waste",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_score.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "familiar-herald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "tmp = next(generate_batch_data_test(all_test_pn, all_test_label, all_test_id[0:5], all_test_user_pos, batch_size))\n",
    "print(len(tmp[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "id": "thrown-possible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "tmp1 = next(generate_batch_data_train(all_train_pn, all_label, all_train_id, all_user_pos, batch_size))\n",
    "print(len(tmp1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "hybrid-farming",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([171, 172,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp1[0][23][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "square-george",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([475, 486, 273, 273, 139, 314, 487, 255, 488,  17,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[0][50][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greatest-excitement",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "accredited-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrhistoryt of [auc, mrr, ndcg@5, ndcg@10]\n",
    "best_metric = [0., 0., 0., 0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "swiss-restoration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1a63aa74e2d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtraingen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerate_batch_data_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_train_pn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_train_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_user_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraingen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_epoch' is not defined"
     ]
    }
   ],
   "source": [
    "# test\n",
    "batch_size = 32\n",
    "for ep in range(2):\n",
    "    traingen=generate_batch_data_train(all_train_pn, all_label, all_train_id, all_user_pos, batch_size)\n",
    "    model.fit_generator(traingen, epochs=1, steps_per_epoch=25)\n",
    "    testgen=generate_batch_data_test(all_test_pn, all_test_label, all_test_id, all_test_user_pos, batch_size)\n",
    "    click_score = model_test.predict_generator(testgen, steps=len(all_test_id)//batch_size, verbose=1)\n",
    "\n",
    "    all_auc=[]\n",
    "    all_mrr=[]\n",
    "    all_ndcg=[]\n",
    "    all_ndcg2=[]\n",
    "    for m in all_test_index:\n",
    "        if np.sum(all_test_label[m[0]:m[1]])!=0 and m[1]<len(click_score):\n",
    "            all_auc.append(roc_auc_score(all_test_label[m[0]:m[1]], click_score[m[0]:m[1],0]))\n",
    "            all_mrr.append(mrr_score(all_test_label[m[0]:m[1]], click_score[m[0]:m[1],0]))\n",
    "            all_ndcg.append(ndcg_score(all_test_label[m[0]:m[1]], click_score[m[0]:m[1],0],k=5))\n",
    "            all_ndcg2.append(ndcg_score(all_test_label[m[0]:m[1]], click_score[m[0]:m[1],0],k=10))\n",
    "    results.append([np.mean(all_auc),np.mean(all_mrr),np.mean(all_ndcg),np.mean(all_ndcg2)])\n",
    "    \n",
    "    metric = [np.mean(all_auc),np.mean(all_mrr),np.mean(all_ndcg),np.mean(all_ndcg2)]\n",
    "    if metric[0] > best_metric[0] and np.mean(metric) > np.mean(best_metric):\n",
    "        best_metric = metric\n",
    "        print('Best model: True')\n",
    "        print(metric)\n",
    "    else:\n",
    "        print('Best model: False')\n",
    "        print(f'AUC: {metric[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "transparent-monkey",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 1)"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "click_score.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "funny-vatican",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90, 95]\n",
      "[1 0 0 0 0]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(m)\n",
    "print(all_test_label[m[0]:m[1]])\n",
    "print(click_score[m[0]:m[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "third-exploration",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "81/81 [==============================] - 25s 306ms/step - loss: 1.6565 - acc: 0.2122\n",
      "2/2 [==============================] - 2s 960ms/step\n",
      "Best model: True\n",
      "[0.3958333333333333, 0.35000000000000003, 0.5084868257705297, 0.5084868257705297]\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 148ms/step - loss: 1.6096 - acc: 0.1933\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Best model: True\n",
      "[0.6041666666666666, 0.5236111111111111, 0.6418834579783793, 0.6418834579783793]\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 149ms/step - loss: 1.6108 - acc: 0.2087\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Best model: False\n",
      "AUC: 0.3750\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 1.6056 - acc: 0.2226\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: True\n",
      "[0.6666666666666666, 0.5583333333333333, 0.669482037067506, 0.669482037067506]\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 1.6052 - acc: 0.2126\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.6042\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 1.6026 - acc: 0.2149\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Best model: False\n",
      "AUC: 0.3750\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 1.5926 - acc: 0.2519\n",
      "2/2 [==============================] - 0s 80ms/step\n",
      "Best model: False\n",
      "AUC: 0.3750\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 1.5794 - acc: 0.2492\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.5417\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 1.5480 - acc: 0.2998\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.3958\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 153ms/step - loss: 1.5143 - acc: 0.2998\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.6250\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 1.4583 - acc: 0.3831\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.6250\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 1.4009 - acc: 0.4286\n",
      "2/2 [==============================] - 0s 59ms/step\n",
      "Best model: False\n",
      "AUC: 0.6042\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 1.2920 - acc: 0.4610\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: False\n",
      "AUC: 0.5417\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 150ms/step - loss: 1.1777 - acc: 0.4850\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.5208\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 153ms/step - loss: 1.0889 - acc: 0.5320\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5208\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 153ms/step - loss: 1.0550 - acc: 0.5370\n",
      "2/2 [==============================] - 0s 75ms/step\n",
      "Best model: False\n",
      "AUC: 0.5625\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 153ms/step - loss: 1.0036 - acc: 0.5648\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.5000\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.9852 - acc: 0.5745\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Best model: True\n",
      "[0.7291666666666666, 0.6416666666666667, 0.7316368389957429, 0.7316368389957429]\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.9468 - acc: 0.5965\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5625\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.9043 - acc: 0.6258\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.5833\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.8793 - acc: 0.6285\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Best model: False\n",
      "AUC: 0.4583\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 153ms/step - loss: 0.8467 - acc: 0.6462\n",
      "2/2 [==============================] - 0s 69ms/step\n",
      "Best model: False\n",
      "AUC: 0.5417\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.8095 - acc: 0.6647\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Best model: False\n",
      "AUC: 0.5000\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.7857 - acc: 0.6806\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.5833\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.7426 - acc: 0.7122\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5208\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.7259 - acc: 0.7199\n",
      "2/2 [==============================] - 0s 73ms/step\n",
      "Best model: False\n",
      "AUC: 0.5417\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.6773 - acc: 0.7369\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.5000\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.6560 - acc: 0.7434\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5208\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.6462 - acc: 0.7593\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Best model: False\n",
      "AUC: 0.5208\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.6038 - acc: 0.7820\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: False\n",
      "AUC: 0.5625\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.5973 - acc: 0.7728\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.5625\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.5587 - acc: 0.7897\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.5208\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.5478 - acc: 0.7894\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.5417\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 150ms/step - loss: 0.5416 - acc: 0.7990\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5208\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.5166 - acc: 0.8094\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5000\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.5121 - acc: 0.8144\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5417\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 153ms/step - loss: 0.4944 - acc: 0.8194\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.5625\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.4569 - acc: 0.8326\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5625\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.4429 - acc: 0.8445\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5521\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.4401 - acc: 0.8399\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Best model: False\n",
      "AUC: 0.5729\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.4259 - acc: 0.8515\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5833\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.4082 - acc: 0.8561\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Best model: False\n",
      "AUC: 0.6250\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.3963 - acc: 0.8553\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.6667\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.4004 - acc: 0.8557\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.6667\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 153ms/step - loss: 0.3833 - acc: 0.8696\n",
      "2/2 [==============================] - 0s 71ms/step\n",
      "Best model: False\n",
      "AUC: 0.5833\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.3464 - acc: 0.8727\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.6146\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.3553 - acc: 0.8688\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: False\n",
      "AUC: 0.6146\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.3428 - acc: 0.8819\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: False\n",
      "AUC: 0.6458\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.3205 - acc: 0.8862\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.6562\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.3282 - acc: 0.8808\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.5938\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.3117 - acc: 0.8897\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Best model: False\n",
      "AUC: 0.5938\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2917 - acc: 0.9020\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.6562\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.3108 - acc: 0.8866\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5938\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2964 - acc: 0.8951\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5729\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2922 - acc: 0.8970\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.6146\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.3081 - acc: 0.8877\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.5729\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 153ms/step - loss: 0.2771 - acc: 0.9008\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.5938\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2685 - acc: 0.9059\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.5938\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2678 - acc: 0.9043\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2485 - acc: 0.9128\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Best model: False\n",
      "AUC: 0.5938\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.2434 - acc: 0.9101\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.6771\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2474 - acc: 0.9174\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.2444 - acc: 0.9101\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Best model: False\n",
      "AUC: 0.6146\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2322 - acc: 0.9194\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2383 - acc: 0.9167\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2233 - acc: 0.9205\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.2251 - acc: 0.9201\n",
      "2/2 [==============================] - 0s 68ms/step\n",
      "Best model: False\n",
      "AUC: 0.6979\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2099 - acc: 0.9236\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.6562\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2296 - acc: 0.9178\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.6979\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.2242 - acc: 0.9209\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1989 - acc: 0.9309\n",
      "2/2 [==============================] - 0s 72ms/step\n",
      "Best model: False\n",
      "AUC: 0.6771\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.2156 - acc: 0.9205\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.2028 - acc: 0.9317\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1868 - acc: 0.9333\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.2003 - acc: 0.9336\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.6562\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.1871 - acc: 0.9344\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: False\n",
      "AUC: 0.6771\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1862 - acc: 0.9321\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.6354\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1650 - acc: 0.9448\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: False\n",
      "AUC: 0.7292\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1800 - acc: 0.9402\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Best model: False\n",
      "AUC: 0.6562\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1666 - acc: 0.9417\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: False\n",
      "AUC: 0.6771\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.1617 - acc: 0.9421\n",
      "2/2 [==============================] - 0s 67ms/step\n",
      "Best model: False\n",
      "AUC: 0.7188\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1761 - acc: 0.9398\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.7188\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1562 - acc: 0.9452\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.7188\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1587 - acc: 0.9464\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: True\n",
      "[0.7395833333333334, 0.6486111111111111, 0.7367706982994804, 0.7367706982994804]\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1643 - acc: 0.9448\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: True\n",
      "[0.7604166666666666, 0.6902777777777778, 0.7675265521685256, 0.7675265521685256]\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1522 - acc: 0.9460\n",
      "2/2 [==============================] - 0s 61ms/step\n",
      "Best model: False\n",
      "AUC: 0.6667\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1590 - acc: 0.9429\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.7188\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.1535 - acc: 0.9437\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Best model: False\n",
      "AUC: 0.6979\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.1612 - acc: 0.9406\n",
      "2/2 [==============================] - 0s 76ms/step\n",
      "Best model: True\n",
      "[0.7916666666666666, 0.7458333333333332, 0.8091932188351922, 0.8091932188351922]\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1538 - acc: 0.9460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.7604\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1534 - acc: 0.9464\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.8021\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1236 - acc: 0.9603\n",
      "2/2 [==============================] - 0s 62ms/step\n",
      "Best model: False\n",
      "AUC: 0.7604\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1410 - acc: 0.9487\n",
      "2/2 [==============================] - 0s 65ms/step\n",
      "Best model: False\n",
      "AUC: 0.7396\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1297 - acc: 0.9502\n",
      "2/2 [==============================] - 0s 60ms/step\n",
      "Best model: False\n",
      "AUC: 0.7917\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1345 - acc: 0.9533\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.7396\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1353 - acc: 0.9545\n",
      "2/2 [==============================] - 0s 70ms/step\n",
      "Best model: False\n",
      "AUC: 0.7812\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1352 - acc: 0.9525\n",
      "2/2 [==============================] - 0s 66ms/step\n",
      "Best model: False\n",
      "AUC: 0.7812\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1260 - acc: 0.9552\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.7708\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 152ms/step - loss: 0.1289 - acc: 0.9525\n",
      "2/2 [==============================] - 0s 64ms/step\n",
      "Best model: False\n",
      "AUC: 0.7292\n",
      "Epoch 1/1\n",
      "81/81 [==============================] - 12s 151ms/step - loss: 0.1285 - acc: 0.9522\n",
      "2/2 [==============================] - 0s 63ms/step\n",
      "Best model: False\n",
      "AUC: 0.7708\n"
     ]
    }
   ],
   "source": [
    "# full n_ecoch\n",
    "for ep in range(n_epoch):\n",
    "    traingen=generate_batch_data_train(all_train_pn, all_label, all_train_id, all_user_pos, batch_size)\n",
    "    model.fit_generator(traingen, epochs=1, steps_per_epoch=len(all_train_id)//batch_size)\n",
    "    testgen=generate_batch_data_test(all_test_pn, all_test_label, all_test_id, all_test_user_pos, batch_size)\n",
    "    click_score = model_test.predict_generator(testgen, steps=len(all_test_id)//batch_size, verbose=1)\n",
    "\n",
    "    all_auc=[]\n",
    "    all_mrr=[]\n",
    "    all_ndcg=[]\n",
    "    all_ndcg2=[]\n",
    "    for m in all_test_index:\n",
    "        if np.sum(all_test_label[m[0]:m[1]])!=0 and m[1]<len(click_score):\n",
    "            all_auc.append(roc_auc_score(all_test_label[m[0]:m[1]], click_score[m[0]:m[1],0]))\n",
    "            all_mrr.append(mrr_score(all_test_label[m[0]:m[1]], click_score[m[0]:m[1],0]))\n",
    "            all_ndcg.append(ndcg_score(all_test_label[m[0]:m[1]], click_score[m[0]:m[1],0],k=5))\n",
    "            all_ndcg2.append(ndcg_score(all_test_label[m[0]:m[1]], click_score[m[0]:m[1],0],k=10))\n",
    "    results.append([np.mean(all_auc),np.mean(all_mrr),np.mean(all_ndcg),np.mean(all_ndcg2)])\n",
    "    \n",
    "    metric = [np.mean(all_auc),np.mean(all_mrr),np.mean(all_ndcg),np.mean(all_ndcg2)]\n",
    "    if metric[0] > best_metric[0] and np.mean(metric) > np.mean(best_metric):\n",
    "        best_metric = metric\n",
    "        print('Best model: True')\n",
    "        print(metric)\n",
    "    else:\n",
    "        print('Best model: False')\n",
    "        print(f'AUC: {metric[0]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "prerequisite-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'model' : model,\n",
    "    'model_test' : model_test\n",
    "}\n",
    "file = open('model_ver1.pkl', 'wb')\n",
    "pickle.dump(model_dict, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ideal-browser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataloader.pkl\tphobert_embed_mat.pkl\r\n",
      "model_ver1.pkl\tphobert_news_preprocess.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
